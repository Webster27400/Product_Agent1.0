import streamlit as st
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.groq import Groq
from llama_index.core.agent import ReActAgent
from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool
import os
from datetime import datetime

# --- Konfiguracja klucza API ---
if "GROQ_API_KEY" in st.secrets:
    os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]
else:
    st.error("Nie znaleziono klucza GROQ_API_KEY w sekretach.")
    st.stop()

# --- Interfejs Aplikacji Streamlit ---
st.title("ğŸ’¡ Agent Automatyk (Wersja Premium)")
st.markdown("Agent, ktÃ³ry analizuje dane i zapisuje dla Ciebie raporty.")

language = st.sidebar.radio(
    "Wybierz jÄ™zyk odpowiedzi:",
    ('Polski', 'Angielski')
)

# --- Dynamiczna Konfiguracja Agenta ---
prompt_pl = "JesteÅ› polskim, proaktywnym asystentem menedÅ¼era produktu. Twoim celem jest analiza danych i identyfikacja ryzyk oraz szans. Zawsze, bezwzglÄ™dnie odpowiadaj TYLKO w jÄ™zyku polskim."
prompt_en = "You are a proactive assistant to a product manager. Your goal is to analyze data and identify risks and opportunities. Always, without exception, respond ONLY in English."

system_prompt = prompt_pl if language == 'Polski' else prompt_en

# POPRAWKA 1: UÅ¼ywamy znacznie potÄ™Å¼niejszego modelu Llama 3 70B
Settings.llm = Groq(model="llama3-70b-8192", system_prompt=system_prompt)
Settings.embed_model = "local:BAAI/bge-small-en-v1.5"

# --- Åadowanie danych (cachowane) ---
@st.cache_resource
def load_index():
    with st.spinner("WczytujÄ™ i indeksujÄ™ dane (tylko raz)..."):
        reader = SimpleDirectoryReader(input_dir=".")
        documents = reader.load_data()
        index = VectorStoreIndex.from_documents(documents)
        return index

index = load_index()
query_engine = index.as_query_engine(llm=Settings.llm)

# --- Tworzenie narzÄ™dzi z BARDZO PRECYZYJNYMI OPISAMI ---

def get_todays_date(fake_arg: str = "") -> str:
    """Zwraca dzisiejszÄ… datÄ™."""
    return datetime.now().strftime("%Y-%m-%d")

# POPRAWKA 2: Bardziej precyzyjny opis narzÄ™dzia do zapisu
def save_report(filename: str, content: str) -> str:
    """UÅ¼yj tego narzÄ™dzia do zapisania tekstu (content) w pliku o podanej nazwie (filename).
    Tego narzÄ™dzia naleÅ¼y uÅ¼yÄ‡ DOPIERO WTEDY, gdy masz juÅ¼ treÅ›Ä‡ do zapisania, uzyskanÄ… za pomocÄ… innego narzÄ™dzia."""
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    return f"Raport zostaÅ‚ pomyÅ›lnie zapisany w pliku {filename}."

date_tool = FunctionTool.from_defaults(fn=get_todays_date, name="narzedzie_daty", description="Zwraca dzisiejszÄ… datÄ™.")
# POPRAWKA 2: Bardziej precyzyjny opis narzÄ™dzia do analizy
document_tool = QueryEngineTool(
    query_engine=query_engine,
    metadata=ToolMetadata(
        name="analizator_dokumentow_klientow",
        description="UÅ¼yj tego narzÄ™dzia, aby uzyskaÄ‡ lub podsumowaÄ‡ informacje z dokumentÃ³w o feedbacku od klientÃ³w, zanim uÅ¼yjesz innych narzÄ™dzi.",
    ),
)
file_writer_tool = FunctionTool.from_defaults(fn=save_report, name="narzedzie_do_zapisu_raportu", description="SÅ‚uÅ¼y do zapisywania raportÃ³w w plikach tekstowych.")

# --- Tworzenie Agenta ---
agent = ReActAgent.from_tools(tools=[date_tool, document_tool, file_writer_tool], llm=Settings.llm, verbose=True)

# --- Logika Czatu ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Twoje pytanie:"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Agent myÅ›li... ğŸ¤”"):
            response = agent.chat(prompt)
            st.write(str(response))
            st.session_state.messages.append({"role": "assistant", "content": str(response)})