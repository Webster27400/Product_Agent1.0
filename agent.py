import streamlit as st
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.groq import Groq
import os

# --- Konfiguracja klucza API ---
os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]

# --- Interfejs Aplikacji Streamlit ---
st.title("ğŸ’¡ Agent Geneza")
st.markdown("Zadaj pytanie dotyczÄ…ce danych z plikÃ³w `data.csv` i `notatki.txt`.")

# PrzeÅ‚Ä…cznik jÄ™zyka w panelu bocznym
language = st.sidebar.radio(
    "Wybierz jÄ™zyk odpowiedzi:",
    ('Polski', 'Angielski')
)

# --- Dynamiczna Konfiguracja Agenta ---
# Definiujemy instrukcje systemowe dla obu jÄ™zykÃ³w
prompt_pl = "JesteÅ› proaktywnym asystentem menedÅ¼era produktu. Twoim celem jest nie tylko odpowiadaÄ‡ na pytania, ale takÅ¼e identyfikowaÄ‡ potencjalne ryzyka i szanse. Odpowiadaj zawsze po polsku, w przyjaznym, ale profesjonalnym tonie."
prompt_en = "You are a proactive assistant to a product manager. Your goal is not only to answer questions but also to identify potential risks and opportunities. Always respond in English, in a friendly yet professional tone."

# Wybieramy instrukcjÄ™ na podstawie przeÅ‚Ä…cznika
system_prompt = prompt_pl if language == 'Polski' else prompt_en

# Ustawiamy modele z wybranÄ… instrukcjÄ…
Settings.llm = Groq(
    model="llama3-8b-8192",
    system_prompt=system_prompt
)
Settings.embed_model = "local:BAAI/bge-small-en-v1.5"

# Åadowanie i indeksowanie danych (ta czÄ™Å›Ä‡ jest cachowana)
@st.cache_resource
def load_index():
    with st.spinner("WczytujÄ™ i indeksujÄ™ dane (tylko raz)..."):
        reader = SimpleDirectoryReader(input_dir=".")
        documents = reader.load_data()
        index = VectorStoreIndex.from_documents(documents)
        return index

index = load_index()
query_engine = index.as_query_engine(llm=Settings.llm) # Przekazujemy zaktualizowany LLM

# Pytanie od uÅ¼ytkownika i odpowiedÅº
user_question = st.text_input("Twoje pytanie:")

if user_question:
    with st.spinner("Agent myÅ›li... ğŸ¤”"):
        response = query_engine.query(user_question)
        st.markdown(f"### OdpowiedÅº Agenta ({language}):")
        st.write(str(response))